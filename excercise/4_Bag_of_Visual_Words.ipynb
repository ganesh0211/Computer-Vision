{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "ECMM426/ECMM441 - Bag of Visual Words.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lrp4DDynMvMu"
   },
   "source": [
    "<H2 style=\"text-align: center\">Bag of Visual Words</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUH4AaYaMvw6"
   },
   "source": [
    "In Computer Vision, Bag of visual words (BOVW) is commonly used in image classification. The concept of BOVW is adapted from information retrieval and the bag of words (BOW) concept of Natural Language Processing.\n",
    "\n",
    "The general idea of BOVW is to represent an image as a set of features. Features consists of keypoints and descriptors. Keypoints are the “stand out” points in an image, so no matter the image is rotated, shrink, or expand, its keypoints will always be the same. And descriptor is the description of the keypoint. We use the keypoints and descriptors to construct vocabularies and represent each image as a frequency histogram of features that are in the image. From the frequency histogram, later, we can find another similar images or predict the category of the image. In this workshop, we are expected to develop an image classifier based on BOVW model using Python.\n",
    "\n",
    "![none](https://www.robots.ox.ac.uk/~vgg/research/encoding_eval/images/flow_web.png)\n",
    "\n",
    "An example of a typical bag of words classification pipeline. Figure by [Chatfield et al.](https://www.robots.ox.ac.uk/~vgg/research/encoding_eval/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8xrhyRec_Bsj"
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.pairwise import chi2_kernel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# opencv contrib version is needed because of sift (issues related to patent)\n",
    "!pip3 install opencv-contrib-python==4.4.0.42\n",
    "import cv2"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGomHDFBN4Tu"
   },
   "source": [
    "## Dataset\n",
    "We are given a dataset which contains variable number of instances per class, there are 7 classes: City, Face, Greenery, Building, House Indoor, Office, Sea. The dataset is also divided into two as training and test. We are expected to train our classifier using the training image set and test it using the test image set."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wmAtfzPLl6PW"
   },
   "source": [
    "if not os.path.exists('bovw7.zip'):\n",
    "    !wget --no-check-certificate https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/bovw7.zip\n",
    "    !unzip -q bovw7.zip"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbB5M4CKOH0h"
   },
   "source": [
    "## Utils\n",
    "Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DBm5PJtbwkoB"
   },
   "source": [
    "# Return the image files\n",
    "def getFiles(path, shuffle=False):\n",
    "    images = []\n",
    "    count = 0\n",
    "    for folder in os.listdir(path):\n",
    "        for file in  os.listdir(os.path.join(path, folder)):\n",
    "            images.append(os.path.join(path, os.path.join(folder, file)))\n",
    "    if shuffle:\n",
    "        np.random.shuffle(images)\n",
    "    return images\n",
    "\n",
    "# Return the train and test splits of bovw data\n",
    "def getSplits(path):\n",
    "    train_images = getFiles(os.path.join(path, 'train'), True)\n",
    "    test_images = getFiles(os.path.join(path, 'test'), False)\n",
    "    train_classes = np.unique([tr_im.split('/')[2] for tr_im in train_images], return_inverse=True)[1]\n",
    "    test_classes = np.unique([te_im.split('/')[2] for te_im in test_images], return_inverse=True)[1]\n",
    "    return train_images, train_classes, test_images, test_classes\n",
    "\n",
    "# Compute image descriptors\n",
    "def getDescriptors(sift, img):\n",
    "    kp, des = sift.detectAndCompute(img, None)\n",
    "    return des\n",
    "\n",
    "# Read image\n",
    "def readImage(img_path):\n",
    "    img = cv2.imread(img_path, 0)\n",
    "    return cv2.resize(img,(150,150))\n",
    "\n",
    "# Gather the image descriptors\n",
    "def vstackDescriptors(descriptor_list):\n",
    "    descriptors = np.array(descriptor_list[0])\n",
    "    for descriptor in descriptor_list[1:]:\n",
    "        descriptors = np.vstack((descriptors, descriptor)) \n",
    "    return descriptors\n",
    "\n",
    "# Cluster the image descriptors\n",
    "def clusterDescriptors(descriptors, no_clusters):\n",
    "    kmeans = KMeans(n_clusters = no_clusters).fit(descriptors)\n",
    "    return kmeans\n",
    "\n",
    "# Compute BOVW features for image\n",
    "def extractFeatures(kmeans, descriptor_list, image_count, no_clusters):\n",
    "    im_features = np.array([np.zeros(no_clusters) for i in range(image_count)])\n",
    "    for i in range(image_count):\n",
    "        for j in range(len(descriptor_list[i])):\n",
    "            feature = descriptor_list[i][j]\n",
    "            feature = feature.reshape(1, 128)\n",
    "            idx = kmeans.predict(feature)\n",
    "            im_features[i][idx] += 1\n",
    "    return im_features\n",
    "\n",
    "# Normalize the image features\n",
    "def normalizeFeatures(scale, features):\n",
    "    return scale.transform(features)\n",
    "\n",
    "# Plot histogram\n",
    "def plotHistogram(im_features, no_clusters):\n",
    "    x_scalar = np.arange(no_clusters)\n",
    "    y_scalar = np.array([abs(np.sum(im_features[:,h], dtype=np.int32)) for h in range(no_clusters)])\n",
    "\n",
    "    plt.bar(x_scalar, y_scalar)\n",
    "    plt.xlabel(\"Visual Word Index\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Complete Vocabulary Generated\")\n",
    "    plt.xticks(x_scalar + 0.4, x_scalar)\n",
    "    plt.show()\n",
    "\n",
    "# Parameter selection of SVM\n",
    "def svcParamSelection(X, y, kernel, nfolds):\n",
    "    Cs = [0.5, 0.1, 0.15, 0.2, 0.3]\n",
    "    gammas = [0.1, 0.11, 0.095, 0.105]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(SVC(kernel=kernel), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "# Train SVM\n",
    "def trainSVM(im_features, train_labels, kernel):\n",
    "    features = im_features\n",
    "    if(kernel == \"precomputed\"):\n",
    "        features = np.dot(im_features, im_features.T)\n",
    "    \n",
    "    params = svcParamSelection(features, train_labels, kernel, 5)\n",
    "    C_param, gamma_param = params.get(\"C\"), params.get(\"gamma\")\n",
    "    print(C_param, gamma_param)\n",
    "    class_weight = {\n",
    "        0: (807 / (7 * 140)),\n",
    "        1: (807 / (7 * 140)),\n",
    "        2: (807 / (7 * 133)),\n",
    "        3: (807 / (7 * 70)),\n",
    "        4: (807 / (7 * 42)),\n",
    "        5: (807 / (7 * 140)),\n",
    "        6: (807 / (7 * 142)) \n",
    "    }\n",
    "  \n",
    "    svm = SVC(kernel = kernel, C =  C_param, gamma = gamma_param, class_weight = class_weight)\n",
    "    svm.fit(features, train_labels)\n",
    "    return svm\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plotConfusionMatrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "# Just wrap up the above function\n",
    "def plotConfusions(true, predictions):\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    class_names = [\"city\", \"face\", \"green\", \"house_building\", \"house_indoor\", \n",
    "                   \"office\", \"sea\"]\n",
    "    plotConfusionMatrix(true, predictions, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "    plotConfusionMatrix(true, predictions, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Compute accuracy\n",
    "def findAccuracy(true, predictions):\n",
    "    print ('accuracy score: %0.3f' % accuracy_score(true, predictions))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ImPiF7DOMcj"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ULG1KlDH0wIs"
   },
   "source": [
    "def trainModel(path, no_descriptors_kmeans, no_clusters, kernel):\n",
    "    train_images, train_classes = getSplits(path)[:2]\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    print(\"Train: Images path detected.\")\n",
    "\n",
    "    descriptor_list = []\n",
    "    for img_path in train_images:\n",
    "        img = readImage(img_path)\n",
    "        des = getDescriptors(sift, img)\n",
    "        descriptor_list.append(des)\n",
    "\n",
    "    descriptors = vstackDescriptors(descriptor_list)\n",
    "    print(\"Train: Descriptors vstacked.\")\n",
    "\n",
    "    random_indices = np.random.choice(descriptors.shape[0], size=no_descriptors_kmeans, replace=False)\n",
    "    descriptors_kmeans = descriptors[random_indices, :]\n",
    "    # vocabulary creation\n",
    "    kmeans = clusterDescriptors(descriptors_kmeans, no_clusters)\n",
    "    print(\"Train: Descriptors clustered.\")\n",
    "\n",
    "    # feature quantization and histogram computation\n",
    "    im_features = extractFeatures(kmeans, descriptor_list, len(train_images), no_clusters)\n",
    "    print(\"Train: Images features extracted.\")\n",
    "\n",
    "    scale = StandardScaler().fit(im_features)        \n",
    "    im_features = scale.transform(im_features)\n",
    "    print(\"Train: Image features normalized.\")\n",
    "\n",
    "    plotHistogram(im_features, no_clusters)\n",
    "    print(\"Train: Histogram features plotted.\")\n",
    "\n",
    "    svm = trainSVM(im_features, train_classes, kernel)\n",
    "    print(\"Train: SVM fitted.\")\n",
    "    print(\"Train: Process completed.\")\n",
    "\n",
    "    return kmeans, scale, svm, im_features"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoksqkjQOPm7"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YDw570aRCJWQ"
   },
   "source": [
    "def testModel(path, kmeans, scale, svm, im_features, no_clusters, kernel):\n",
    "    test_images, test_classes = getSplits(path)[2:]\n",
    "    print(\"Test: Images path detected.\")\n",
    "    count = 0\n",
    "    descriptor_list = []\n",
    "    valid_idx = []\n",
    "    name_dict =\t{\n",
    "        \"0\": \"city\",\n",
    "        \"1\": \"face\",\n",
    "        \"2\": \"green\",\n",
    "        \"3\": \"house_building\",\n",
    "        \"4\": \"house_indoor\",\n",
    "        \"5\": \"office\",\n",
    "        \"6\": \"sea\"\n",
    "    }\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    for i, img_path in enumerate(test_images):\n",
    "        img = readImage(img_path)\n",
    "        des = getDescriptors(sift, img)\n",
    "\n",
    "        if des is not None:\n",
    "            count += 1\n",
    "            descriptor_list.append(des)\n",
    "            valid_idx.append(i)\n",
    "\n",
    "    # remove the images that have zero descriptors\n",
    "    test_classes = test_classes[valid_idx]\n",
    "\n",
    "    descriptors = vstackDescriptors(descriptor_list)\n",
    "    print(\"Test: Descriptors vstacked.\")\n",
    "\n",
    "    test_features = extractFeatures(kmeans, descriptor_list, count, no_clusters)\n",
    "    print(\"Test: Images features extracted.\")\n",
    "\n",
    "    test_features = scale.transform(test_features)\n",
    "    print(\"Test: Image features normalized.\")\n",
    "\n",
    "    kernel_test = test_features\n",
    "    if(kernel == \"precomputed\"):\n",
    "        kernel_test = np.dot(test_features, im_features.T)\n",
    "\n",
    "    predictions = [name_dict[str(int(i))] for i in svm.predict(kernel_test)]\n",
    "    true = [name_dict[str(int(i))] for i in test_classes]\n",
    "    print(\"Test: Images classified.\")\n",
    "\n",
    "    plotConfusions(true, predictions)\n",
    "    print(\"Test: Confusion matrixes plotted.\")\n",
    "\n",
    "    findAccuracy(true, predictions)\n",
    "    print(\"Test: Accuracy calculated.\")\n",
    "    print(\"Test: Execution done.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRt7b7m0PGq1"
   },
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DHundZPk3PVB"
   },
   "source": [
    "# Set some important parameters\n",
    "path = 'bovw7'\n",
    "no_clusters = 500\n",
    "no_descriptors_kmeans = 20000\n",
    "kernel = 'linear'\n",
    "# Training step\n",
    "kmeans, scale, svm, im_features = trainModel(path, no_descriptors_kmeans, no_clusters, kernel)\n",
    "# Test step\n",
    "testModel(path, kmeans, scale, svm, im_features, no_clusters, kernel)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYZOM3-dXdJA"
   },
   "source": [
    "This simple pipeline approximately obtains 60% accuracy on the dataset, which is better than the random performance which should be around 14%."
   ]
  }
 ]
}